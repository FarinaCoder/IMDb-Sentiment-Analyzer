{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# 1. Import the tools\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# 2. Load Data (Directly from a raw GitHub URL)\n",
        "print(\"‚è≥ Downloading dataset... (this may take a moment)\")\n",
        "# We use the 'raw' link so pandas can read it like a normal CSV file\n",
        "url = \"https://raw.githubusercontent.com/bestvater/misc/master/IMDB%20Dataset.csv\"\n",
        "data = pd.read_csv(url)\n",
        "\n",
        "# 3. Clean Data\n",
        "# This dataset is huge (50k reviews), so we just drop any errors\n",
        "data = data.dropna()\n",
        "# The column names in this specific file are 'review' and 'sentiment'\n",
        "# We rename them to be safe so the code below works perfectly\n",
        "data.columns = ['Review', 'Sentiment']\n",
        "\n",
        "# 4. Split Data\n",
        "X = data['Review']\n",
        "y = data['Sentiment']\n",
        "# 80% for training, 20% for testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 5. Vectorize (Translate words to numbers)\n",
        "# We limit to the top 5000 most important words to keep it fast\n",
        "vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
        "X_train_vec = vectorizer.fit_transform(X_train)\n",
        "X_test_vec = vectorizer.transform(X_test)\n",
        "\n",
        "# 6. Train the Brain (Logistic Regression)\n",
        "print(\"üß† Training the model...\")\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train_vec, y_train)\n",
        "\n",
        "# 7. Check the Grade\n",
        "predictions = model.predict(X_test_vec)\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "\n",
        "print(f\"üéâ Success! Model Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "# --- TEST IT YOURSELF ---\n",
        "print(\"\\n--- üçø MOVIE REVIEW JUDGE ---\")\n",
        "my_review = [\"The movie was too long and the plot made no sense.\"]\n",
        "my_vec = vectorizer.transform(my_review)\n",
        "result = model.predict(my_vec)\n",
        "\n",
        "print(f\"Review: '{my_review[0]}'\")\n",
        "print(f\"Verdict: {result[0].upper()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZVICaZKNdjh",
        "outputId": "fd144fb3-d72b-43ea-a138-df9d458690a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚è≥ Downloading dataset... (this may take a moment)\n",
            "üß† Training the model...\n",
            "üéâ Success! Model Accuracy: 88.89%\n",
            "\n",
            "--- üçø MOVIE REVIEW JUDGE ---\n",
            "Review: 'The movie was too long and the plot made no sense.'\n",
            "Verdict: NEGATIVE\n"
          ]
        }
      ]
    }
  ]
}